# í¿—ï¸ Cognitive Architecture

## System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     LumenAI API Gateway                         â”‚
â”‚  â€¢ JWT Authentication  â€¢ GPT-5 Models  â€¢ missingContext         â”‚
â”‚  â€¢ Cryptographic Signatures  â€¢ Usage Tracking                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       CLI & SDK Layer                           â”‚
â”‚  lumen_cli.py  â”‚  lumen_sdk.py  â”‚  Authentication              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                          â”‚                          â”‚
        â–¼                          â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Schema     â”‚         â”‚  Recursive   â”‚         â”‚ Multi-Agent  â”‚
â”‚  Generation  â”‚         â”‚   Research   â”‚         â”‚ Orchestrationâ”‚
â”‚              â”‚         â”‚              â”‚         â”‚              â”‚
â”‚ â€¢ AI-powered â”‚         â”‚ â€¢ Auto-      â”‚         â”‚ â€¢ Specializedâ”‚
â”‚   schema     â”‚         â”‚   explores   â”‚         â”‚   agents     â”‚
â”‚   creation   â”‚         â”‚   missing    â”‚         â”‚ â€¢ Synthesis  â”‚
â”‚ â€¢ Validation â”‚         â”‚   context    â”‚         â”‚ â€¢ Comparison â”‚
â”‚ â€¢ Extraction â”‚         â”‚ â€¢ Builds     â”‚         â”‚ â€¢ Refinement â”‚
â”‚              â”‚         â”‚   knowledge  â”‚         â”‚              â”‚
â”‚              â”‚         â”‚   trees      â”‚         â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                        â”‚                        â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Application Layer   â”‚
                    â”‚                       â”‚
                    â”‚ â€¢ Knowledge Graphs    â”‚
                    â”‚ â€¢ Research Pipelines  â”‚
                    â”‚ â€¢ Data Extraction     â”‚
                    â”‚ â€¢ Comparative Analysisâ”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Components

### 1. Schema-Driven Extraction

**Purpose**: Convert unstructured text into structured data

**Flow**:
```
Natural Language Description
         â†“
    AI generates JSON Schema
         â†“
    Schema validates structure
         â†“
    Extract data from text
         â†“
    Structured JSON output
```

**Example**:
```bash
# Generate schema
$ lumen_cli.py generate-schema "person with name and email"

# Use schema
$ lumen_cli.py validate "John, john@example.com" -f person.json
â†’ {"name": "John", "email": "john@example.com"}
```

### 2. Recursive Research Agent

**Purpose**: Automatically explore knowledge gaps

**Algorithm**:
```python
def research(query, depth=0):
    if depth >= max_depth:
        return result
    
    result = api.query(query)
    missing = result.missingContext
    
    for context_item in missing:
        branch = research(context_item, depth+1)
        result.branches.append(branch)
    
    return result
```

**Key Feature**: The API returns `missingContext` - things it knows it doesn't know. The agent automatically explores these branches.

**Example Output**:
```
Query: "Who won the 2024 Nobel Prize?"
â”œâ”€ Names of laureates
â”‚  â”œâ”€ Official announcement date
â”‚  â””â”€ Prize categories
â”œâ”€ Affiliations of winners
â”‚  â”œâ”€ Institution details
â”‚  â””â”€ Research contributions
â””â”€ Press release information
   â”œâ”€ Citation text
   â””â”€ Prize amount
```

### 3. Multi-Agent Collaboration

**Purpose**: Combine different perspectives for comprehensive analysis

**Pattern**:
```
Topic
  â†“
  â”œâ”€â†’ Technical Agent â†’ Technical perspective
  â”œâ”€â†’ Business Agent â†’ Business perspective  
  â”œâ”€â†’ Ethics Agent â†’ Ethical perspective
  â†“
Synthesis Agent â†’ Combined view
```

**Example**:
```python
# Agent 1: Technical
tech_view = agent.query("Technical aspects of quantum computing")

# Agent 2: Business
biz_view = agent.query("Business applications of quantum computing")

# Agent 3: Synthesizer
synthesis = agent.query(f"Synthesize: {tech_view} and {biz_view}")
```

### 4. Iterative Refinement

**Purpose**: Self-aware agents that fill their own knowledge gaps

**Loop**:
```
1. Query â†’ Get response with missingContext
2. Detect gaps in knowledge
3. Generate follow-up queries
4. Refine answer with new context
5. Repeat until complete or max iterations
```

## Advanced Patterns

### Knowledge Graph Builder

Combines recursive research + schema extraction:

```python
entity_schema = {
    "entities": [{"name": str, "type": str, "description": str}],
    "relationships": [{"from": str, "to": str, "type": str}]
}

# Research topic recursively
tree = researcher.research("neural networks")

# Extract entities at each level
graph = extract_with_schema(tree, entity_schema)
```

### Pipeline Orchestration

Chain multiple agents and schemas:

```
Input â†’ [Schema A] â†’ Agent 1 â†’ Extract Topics
                                     â†“
                              For each topic
                                     â†“
                              [Schema B] â†’ Agent 2 â†’ Deep Research
                                                          â†“
                                                    [Schema C] â†’ Agent 3 â†’ Synthesis
                                                                              â†“
                                                                         Final Output
```

### Comparative Analysis

Parallel research + synthesis:

```
Topic A â”€â†’ Research Agent A â”€â”
                              â”œâ”€â†’ Comparison Agent â†’ Analysis
Topic B â”€â†’ Research Agent B â”€â”˜
```

## Why This Works

1. **missingContext awareness**: The API explicitly tells you what it doesn't know
2. **Schema flexibility**: Generate schemas on-the-fly for any data structure
3. **Composability**: Chain agents and schemas in unlimited ways
4. **Self-improvement**: Agents can refine their own queries

## Use Cases

- í³š **Research Automation**: Deep dive into topics with automatic gap-filling
- í´ **Data Extraction**: Convert unstructured text to structured databases
- í·  **Knowledge Management**: Build comprehensive knowledge graphs
- í´– **Agent Swarms**: Parallel specialized agents for complex tasks
- í´„ **Iterative Refinement**: Self-improving answers through multiple passes

## Performance

- **Free tier**: 50 requests/day, gpt-5-nano only
- **Recursive depth**: Typically 2-3 levels (exponential branches)
- **Response time**: ~1-2 seconds per query
- **Rate limiting**: Built-in delays (configurable)

## Next Steps

1. **Memory Systems**: Add long-term context retention
2. **Agent Swarms**: Parallel exploration of multiple branches
3. **Learning Loop**: Agents that learn from failures
4. **Human-in-the-Loop**: Interactive refinement with user feedback
5. **Cross-API Integration**: Chain with other AI services

---

**This is not just a CLI - it's a cognitive architecture for building truly intelligent agents.**
